{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as K\n",
    "K.tensorflow_backend._get_available_gpus()\n",
    "\n",
    "from pymongo import MongoClient\n",
    "from bson.objectid import ObjectId\n",
    "\n",
    "import time,datetime\n",
    "import os \n",
    "import schedule\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as web\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import style\n",
    "\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "import keras\n",
    "\n",
    "from sklearn import preprocessing\n",
    "\n",
    "from copy import deepcopy\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split a multivariate sequence into samples\n",
    "def split_sequences(sequences, n_steps):\n",
    "    X, y = list(), list()\n",
    "    for i in range(len(sequences[0])):\n",
    "        # find the end of this pattern\n",
    "        end_ix = i + n_steps\n",
    "        # check if we are beyond the dataset\n",
    "        if end_ix > len(sequences[0])-1:\n",
    "            break\n",
    "        # gather input and output parts of the pattern\n",
    "        seq_x = sequences[0][i:end_ix].reshape(len(sequences[0][i:end_ix]),1) \n",
    "        seq_x = np.append(seq_x, sequences[1][i:end_ix].reshape(len(sequences[1][i:end_ix]),1), axis=1)\n",
    "        seq_x = np.append(seq_x, sequences[2][i:end_ix].reshape(len(sequences[2][i:end_ix]),1), axis=1)\n",
    "        seq_y1 =  sequences[0][end_ix]\n",
    "        X.append(seq_x)\n",
    "        y.append(seq_y1)\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def start_daily_prediction():\n",
    "    conn = MongoClient('120.126.136.17')\n",
    "    db = conn.Tracker\n",
    "    collection = [db.james]# db.db2, db.dn2, db.james, db.leo\n",
    "    clean_data = []\n",
    "    for col in collection:\n",
    "        cursor = col.find({})\n",
    "        df = pd.DataFrame(list(cursor))\n",
    "\n",
    "    df.replace('', np.nan, inplace=True)\n",
    "    df.fillna(method='ffill', inplace=True)\n",
    "\n",
    "    df['hr_value'] = df['hr_value'].astype(float)\n",
    "    df['o2_value'] = df['o2_value'].astype(float)\n",
    "    df['latitude'] = df['latitude'].astype(float)\n",
    "    df['longitude'] = df['longitude'].astype(float)\n",
    "    df['step_value'] = df['step_value'].astype(float)\n",
    "\n",
    "    df = df[(df['hr_value'] != 0)]\n",
    "    # map out the weekday\n",
    "    df['weekday'] = df['timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x).strftime('%w'))\n",
    "    df['week'] = df['timestamp'].apply(lambda x: datetime.datetime.fromtimestamp(x).isocalendar()[1]\n",
    "              - (datetime.datetime.fromtimestamp(x).isoweekday() < 7)) # do this so that week may start on sunday\n",
    "\n",
    "    dfsteptotal = pd.DataFrame()\n",
    "    dfsteptotal = df[['week', 'weekday']].set_index(['week', 'weekday'])\n",
    "    dfsteptotal = dfsteptotal[~dfsteptotal.index.duplicated(keep='first')]\n",
    "    dfsteptotal['steps'] = 0\n",
    "    dfsteptotal.reset_index(inplace=True)\n",
    "    dfadd = pd.DataFrame({'week' : [12], 'weekday':['5'], 'steps':[0]})\n",
    "    dfsteptotal = dfsteptotal.append(dfadd, ignore_index=True)\n",
    "    dfsteptotal = dfsteptotal.set_index(['week', 'weekday'])\n",
    "    dfsteptotal.sort_index(inplace=True)\n",
    "\n",
    "    # here I map between integer and the sting it's mean\n",
    "    timeslidemap = {0:'morning', 1:'afternoon', 2:'evening'}\n",
    "    basestamp = df['timestamp'][0]\n",
    "    endstamp = df['timestamp'][-1:].values[0]\n",
    "    # for num, row in df[:30000].iterrows():\n",
    "    while True:\n",
    "        try:\n",
    "            dfbetween = df.loc[df['timestamp'].between(\n",
    "                datetime.datetime.fromtimestamp(basestamp).replace(hour=0,minute=0,second=0).timestamp(),\n",
    "                datetime.datetime.fromtimestamp(basestamp).replace(hour=23,minute=59,second=59).timestamp()\n",
    "                        , inclusive=True)]\n",
    "            steps = dfbetween['step_value'].sum()\n",
    "        #     print(int(datetime.datetime.fromtimestamp(basestamp).strftime('%m')),\n",
    "        #             int(datetime.datetime.fromtimestamp(basestamp).strftime('%d')),\n",
    "        #                 timeslidemap[estimedevide])\n",
    "\n",
    "            dfsteptotal.loc[[(datetime.datetime.fromtimestamp(basestamp).isocalendar()[1] - \n",
    "                                        (datetime.datetime.fromtimestamp(basestamp).isoweekday() < 7),\n",
    "                                datetime.datetime.fromtimestamp(basestamp).strftime('%w'))], \n",
    "                                               ['steps']] += steps\n",
    "\n",
    "            basestamp = (datetime.datetime.fromtimestamp(basestamp) + datetime.timedelta(days=1)).timestamp()\n",
    "            if basestamp > endstamp:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(str(e))\n",
    "            basestamp = (datetime.datetime.fromtimestamp(basestamp) + datetime.timedelta(days=1)).timestamp()\n",
    "    #     else:\n",
    "    #         print(datetime.datetime.fromtimestamp(basestamp) ,datetime.datetime.fromtimestamp(endstamp))\n",
    "\n",
    "\n",
    "    dfsteptotal.loc[(12,'5')] = dfsteptotal.xs('5', level=1).sum() / (dfsteptotal.xs('5', level=1).count() - 1)\n",
    "    dfsteptotal['Comfort'] = 0\n",
    "    dfsteptotal['Precp'] = 0\n",
    "\n",
    "    # add wether \n",
    "    coding = 'utf-8'\n",
    "    table = pd.DataFrame()\n",
    "    basetime = datetime.date(2019,3,27)\n",
    "    num = 0\n",
    "    for index, row in dfsteptotal.iterrows():\n",
    "        try:\n",
    "            # parsing part\n",
    "            date = basetime + datetime.timedelta(days = num)\n",
    "            num += 1\n",
    "            dateStr = date.strftime('%Y-%m-%d')\n",
    "            url = 'https://e-service.cwb.gov.tw/HistoryDataQuery/DayDataController.do?command=viewMain&station=C0AC60'+ \\\n",
    "                '&stname=%25E4%25B8%2589%25E5%25B3%25BD&datepicker=' + dateStr\n",
    "            table = pd.read_html(url,encoding=coding,index_col=0,header=None,flavor='bs4')[1]\n",
    "            # start dataprocess\n",
    "            table.replace('/', np.nan, inplace=True)\n",
    "            table.replace('X', np.nan, inplace=True)  \n",
    "            table.fillna(method='ffill', inplace=True)\n",
    "            table.index -= 1\n",
    "            dfoneday = pd.DataFrame()\n",
    "            # the table data need to reshape and turn to a variable\n",
    "            T = table['temperature'].values.reshape(len(table['temperature'].values)).astype('float')\n",
    "            RH = table['RH'].values.reshape(len(table['RH'].values)).astype('float')\n",
    "            dfoneday['comfort'] = T - 0.55 *(1-RH/100)*(T - 14)\n",
    "            dfoneday['Precp'] = table['Precp']['降水量(mm)']\n",
    "            bins = [0,11,16,20,27,31,60]\n",
    "            labels=[0,1,2,3,4,5]\n",
    "            dfoneday['bins'] = pd.cut(dfoneday['comfort'], bins=bins, labels=labels, include_lowest=True)\n",
    "            # mComfort aComfort eComfort mPrecp aPrecp ePrecp\n",
    "            dfsteptotal.loc[[index], ['Comfort']] = dfoneday['bins'].astype(int).mean()\n",
    "            dfoneday['Precp'].astype(float)\n",
    "            dfsteptotal.loc[[index], ['Precp']] = dfoneday['Precp'].astype(float).sum()\n",
    "        except Exception as e:\n",
    "            if str(e) == \"could not convert string to float: '...'\":\n",
    "                print('some data are not yet ready')\n",
    "                break\n",
    "    print(date)\n",
    "\n",
    "    steps = dfsteptotal['steps'][:-1].values\n",
    "    Comfort = dfsteptotal['Comfort'][:-1].values\n",
    "    Precp = dfsteptotal['Precp'][:-1].values\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    dataset = np.array([steps, Comfort, Precp])\n",
    "\n",
    "    scaler = preprocessing.StandardScaler()\n",
    "    dataset = np.array([steps, Comfort, Precp])\n",
    "    normalized_dataset = scaler.fit_transform(dataset)\n",
    "    n_steps = 3\n",
    "    X, y = split_sequences(normalized_dataset, n_steps)\n",
    "\n",
    "    n_features = 3\n",
    "    model = Sequential()\n",
    "    model.add(keras.layers.LSTM(100,activation='relu', return_sequences=True,input_shape=(n_steps, n_features)))\n",
    "    model.add(keras.layers.LSTM(100, activation='relu'))\n",
    "    model.add(Dense(1))\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "\n",
    "    history = model.fit(X, y, epochs=50, verbose=0, batch_size=128, validation_split=0.2)\n",
    "\n",
    "    newdataset = dataset[:, -3:]\n",
    "    normalized_dataset = scaler.fit_transform(newdataset.reshape(-1,1))\n",
    "    normalized_dataset = normalized_dataset.reshape(1,3,3)\n",
    "\n",
    "    p = model.predict(normalized_dataset)[0]\n",
    "    prediction = int(scaler.inverse_transform(p))\n",
    "    date = basetime + datetime.timedelta(days = num)\n",
    "    dateStr = date.strftime('%Y-%m-%d')\n",
    "    lis = dateStr.split('-')\n",
    "    lis = list(map(int, lis))\n",
    "\n",
    "    conn = MongoClient('120.126.136.17')\n",
    "    db = conn.Tracker\n",
    "    collection = db.prediction# db.db2, db.dn2, db.james, db.leo\n",
    "    mydict = { 'year':lis[0], 'month':lis[1], 'day':lis[2], 'prediction':prediction}\n",
    "    collection.insert_one(mydict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Every 1 day at 02:30:00 do start_prediction() (last run: [never], next run: 2019-04-27 02:30:00)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schedule.every().day.at(\"02:30\").do(start_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "some data are not yet ready\n",
      "2019-04-26\n",
      "some data are not yet ready\n",
      "2019-04-27\n",
      "some data are not yet ready\n",
      "2019-04-28\n",
      "some data are not yet ready\n",
      "2019-04-28\n",
      "some data are not yet ready\n",
      "2019-04-30\n",
      "some data are not yet ready\n",
      "2019-04-30\n"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    schedule.run_pending()\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
